{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0d9db03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea96b852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\n",
      "ERROR: No matching distribution found for tensorflow\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bdc451f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# import pandas as pd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# import seaborn as sns\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# import pandas as pd\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f626c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: c:\\Users\\omkar\\OneDrive\\Desktop\\B Tech\\project\\AICTE-Internship-files-main\\3.Potato Leaf Disease Detection\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "current_directory = os.getcwd()\n",
    "train_path = os.path.join(current_directory, \"dataset\",\"Train\")\n",
    "valid_path = os.path.join(current_directory, \"dataset\",\"Valid\")\n",
    "test_path = os.path.join(current_directory, \"dataset\",\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733d6b84",
   "metadata": {},
   "source": [
    "## Parameter Breakdown\n",
    "\n",
    "### `train_path`\n",
    "- **Description**: The path to the directory containing the training images.\n",
    "- **Details**: This directory should have subdirectories, with each subdirectory named after a class label, containing images of that class.\n",
    "\n",
    "---\n",
    "\n",
    "### `labels=\"inferred\"`\n",
    "- **Description**: The labels for the images are inferred from the subdirectory names in the `train_path`.\n",
    "- **Example**: If `train_path` contains subdirectories `cats` and `dogs`, labels will be assigned as `cats = 0` and `dogs = 1` (or similar).\n",
    "\n",
    "---\n",
    "\n",
    "### `label_mode=\"categorical\"`\n",
    "- **Description**: Specifies the type of labels.\n",
    "  - `\"categorical\"`: Labels are returned as one-hot encoded vectors.\n",
    "  - `\"int\"`: Labels are returned as integers.\n",
    "  - `None`: No labels are returned.\n",
    "- **Details**: Here, labels are one-hot encoded, useful for classification tasks.\n",
    "\n",
    "---\n",
    "\n",
    "### `class_names=None`\n",
    "- **Description**: Automatically determines class names from the subdirectory names.\n",
    "- **Details**: You can specify a list like `['cats', 'dogs']` to manually define the class names.\n",
    "\n",
    "---\n",
    "\n",
    "### `color_mode=\"rgb\"`\n",
    "- **Description**: Specifies the image color mode.\n",
    "  - `\"rgb\"`: Loads 3-channel color images.\n",
    "  - `\"grayscale\"`: Loads single-channel grayscale images.\n",
    "  - `\"rgba\"`: Loads 4-channel color images.\n",
    "- **Details**: Here, images are loaded in RGB mode.\n",
    "\n",
    "---\n",
    "\n",
    "### `batch_size=32`\n",
    "- **Description**: The number of images to be processed in a single batch during training.\n",
    "- **Details**: Affects memory usage and training speed.\n",
    "\n",
    "---\n",
    "\n",
    "### `image_size=(128, 128)`\n",
    "- **Description**: Resizes all images to the specified dimensions (128x128 pixels in this case).\n",
    "- **Details**: Helps standardize input dimensions for the neural network.\n",
    "\n",
    "---\n",
    "\n",
    "### `shuffle=True`\n",
    "- **Description**: Randomly shuffles the images before creating batches.\n",
    "- **Details**: Helps reduce overfitting and ensures a diverse input distribution.\n",
    "\n",
    "---\n",
    "\n",
    "### `seed=None`\n",
    "- **Description**: Used to set a random seed for reproducibility of the shuffle.\n",
    "- **Details**: If `None`, results may vary across runs.\n",
    "\n",
    "---\n",
    "\n",
    "### `validation_split=None`\n",
    "- **Description**: Specifies the fraction of data to be set aside for validation.\n",
    "- **Example**: `validation_split=0.2` reserves 20% of data for validation.\n",
    "\n",
    "---\n",
    "\n",
    "### `subset=None`\n",
    "- **Description**: Specifies whether this dataset is for training or validation when `validation_split` is set.\n",
    "- **Options**: `\"training\"` or `\"validation\"`.\n",
    "- **Details**: Must be used with `validation_split`.\n",
    "\n",
    "---\n",
    "\n",
    "### `interpolation=\"bilinear\"`\n",
    "- **Description**: Method used to resize the images.\n",
    "- **Options**: `\"nearest\"`, `\"bilinear\"`, `\"bicubic\"`, etc.\n",
    "- **Details**: `\"bilinear\"` is smooth and works well for resizing.\n",
    "\n",
    "---\n",
    "\n",
    "### `follow_links=False`\n",
    "- **Description**: If `True`, follows symbolic links to access images.\n",
    "\n",
    "---\n",
    "\n",
    "### `crop_to_aspect_ratio=False`\n",
    "- **Description**: If `True`, crops images to maintain their original aspect ratio before resizing.\n",
    "- **Details**: If `False`, images are resized to `image_size` directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546b587a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# function is used to create an image dataset from a directory structure where images are organized into subdirectories representing class labels\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m training_set \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(\n\u001b[0;32m      3\u001b[0m     train_path,\n\u001b[0;32m      4\u001b[0m     labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     label_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     class_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m      7\u001b[0m     color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# batch_size=32,\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m),\n\u001b[0;32m     10\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# seed=None,\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# validation_split=None,\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# subset=None,\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# follow_links=False,\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# crop_to_aspect_ratio=False\u001b[39;00m\n\u001b[0;32m     17\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# function is used to create an image dataset from a directory structure where images are organized into subdirectories representing class labels\n",
    "training_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    # batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    # seed=None,\n",
    "    # validation_split=None,\n",
    "    # subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    # follow_links=False,\n",
    "    # crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c58a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the class labels\n",
    "labels = training_set.class_names\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d60128",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = tf.keras.utils.image_dataset_from_directory(\n",
    "    valid_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    # batch_size=32,\n",
    "    image_size=(128, 128),\n",
    "    shuffle=True,\n",
    "    # seed=None,\n",
    "    # validation_split=None,\n",
    "    # subset=None,\n",
    "    interpolation=\"bilinear\",\n",
    "    # follow_links=False,\n",
    "    # crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89cade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding='same',activation='relu',input_shape=[128,128,3]))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3,padding='same',activation='relu',input_shape=[128,128,3]))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=512,kernel_size=3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=512,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(units=1500,activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dropout(0.4))\n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units=3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace6f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b29c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ae5aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history = cnn.fit(x=training_set,validation_data=validation_set,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bc4919",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = cnn.evaluate(training_set)\n",
    "print('Training accuracy:', train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f92b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = cnn.evaluate(validation_set)\n",
    "print('Validation accuracy:', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d15da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('trained_plant_disease_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430810a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5556213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [i for i in range(1,11)]\n",
    "plt.plot(epochs,training_history.history['accuracy'],color='brown',label='Training Accuracy')\n",
    "plt.plot(epochs,training_history.history['val_accuracy'],color='green',label='Validation Accuracy')\n",
    "plt.xlabel('No. of Epochs')\n",
    "plt.title('Visualization of Accuracy Result')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e83c2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
